---
title: "Project 8 Template"
output:
  html_document: default
---

```{r}
# Add to this package list for additional SL algorithms
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  tidyverse,
  ggthemes,
  ltmle,
  tmle,
  SuperLearner,
  tidymodels,
  caret,
  dagitty,
  ggdag,
  here)
# Set a CRAN mirror
options(repos = c(CRAN = "https://cloud.r-project.org"))
#install.packages(c("future", "furrr"))
library(here)
here()
#REMINDER: Change here on desktop
heart_disease <- readr::read_csv(here("heart_disease_tmle.csv"))
colnames(heart_disease)
# set seed
# ----------
set.seed(44)
```

# Introduction

Heart disease is the leading cause of death in the United States, and treating it properly is an important public health goal. However, it is a complex disease with several different risk factors and potential treatments. Physicians typically recommend changes in diet, increased exercise, and/or medication to treat symptoms, but it is difficult to determine how effective any one of these factors is in treating the disease. In this project, you will explore SuperLearner, Targeted Maximum Likelihood Estimation (TMLE), and Longitudinal Targeted Maximum Likelihood Estimation (LTMLE). Using a simulated dataset, you will explore whether taking blood pressure medication reduces mortality risk. 

# Data

This dataset was simulated using R (so it does not come from a previous study or other data source). It contains several variables:

\begin{itemize}
    \item \textbf{blood\_pressure\_medication}: Treatment indicator for whether the individual took blood pressure medication (0 for control, 1 for treatment)
    \item \textbf{mortality}: Outcome indicator for whether the individual passed away from complications of heart disease (0 for no, 1 for yes)
    \item \textbf{age}: Age at time 1
    \item \textbf{sex\_at\_birth}: Sex assigned at birth (0 female, 1 male)
    \item \textbf{simplified\_race}: Simplified racial category. (1: White/Caucasian, 2: Black/African American, 3: Latinx, 4: Asian American, \newline 5: Mixed Race/Other)
    \item \textbf{income\_thousands}: Household income in thousands of dollars
    \item \textbf{college\_educ}: Indicator for college education (0 for no, 1 for yes)
    \item \textbf{bmi}: Body mass index (BMI)
    \item \textbf{chol}: Cholesterol level
    \item \textbf{blood\_pressure}: Systolic blood pressure 
    \item \textbf{bmi\_2}: BMI measured at time 2
    \item \textbf{chol\_2}: Cholesterol measured at time 2
    \item \textbf{blood\_pressure\_2}: BP measured at time 2
    \item \textbf{blood\_pressure\_medication\_2}: Whether the person took treatment at time period 2 
\end{itemize}

For the "SuperLearner" and "TMLE" portions, you can ignore any variable that ends in "\_2", we will reintroduce these for LTMLE.

# SuperLearner

## Modeling

Fit a SuperLearner model to estimate the probability of someone dying from complications of heart disease, conditional on treatment and the relevant covariates. Do the following:

\begin{enumerate}
    \item Choose a library of at least 5 machine learning algorithms to evaluate. \textbf{Note}: We did not cover how to hyperparameter tune constituent algorithms within SuperLearner in lab, but you are free to do so if you like (though not required to for this exercise). 
    \item Split your data into train and test sets.
    \item Train SuperLearner
    \item Report the risk and coefficient associated with each model, and the performance of the discrete winner and SuperLearner ensemble
    \item Create a confusion matrix and report your overall accuracy, recall, and precision
\end{enumerate}

```{r}
# Fit SuperLearner Model
#listWrappers()
## sl lib
#install.packages("SuperLearner")
#install.packages(c("gam", "earth"))
#install.packages("ranger")
library("SuperLearner")
#Picking different algorithms because three had coefficients of zero lol
sl_libs <- c('SL.mean', 'SL.glm', 'SL.earth', 'SL.ranger', 'SL.step')

library(future)
#library(furrr)
## Train/Test split
# initial split
# ----------
heart_split <- 
  initial_split(heart_disease, prop = 3/4) # create initial split (tidymodels)


# Training 
# ----------
train <- 
  # Declare the training set with rsample::training()
  training(heart_split)

# y_train 
y_train <- train %>% 
  pull(mortality)  

# x_train  
x_train <-
  train %>%
  # drop the target variable
  select(-mortality, -ends_with("_2"))  

# Testing 
# ----------
test <-  
  # Declare the training set with rsample::training()
  testing(heart_split)

# y test
y_test <- test %>%
  pull(mortality)

# x test
x_test <- 
  test %>%
  select(-mortality, -ends_with("_2"))

## Train SuperLearner
# LASSO 
# ----------
sl_lasso <- SuperLearner(Y = y_train,              # target
                         X = x_train,              # features
                         family = binomial(),      # binomial : 1,0s
                         SL.library = "SL.glmnet") # find the glmnet algo from SL

# view
sl_lasso
## Risk and Coefficient of each model
# Here is the risk of the best model (discrete SuperLearner winner).
# Use which.min boolean to find minimum cvRisk in list
sl_lasso$cvRisk[which.min(sl_lasso$cvRisk)]
## Discrete winner and superlearner ensemble performance
# set seed
set.seed(987)

# multiple models  
# ----------
sl = SuperLearner(Y = y_train,
                  X = x_train,
                  family = binomial(),
                  # notice these models are concatenated
                  SL.library =sl_libs)
sl
# predictions
# ----------
preds <- 
  predict(sl,             # use the superlearner not individual models
          x_test,         # prediction on test set
          onlySL = TRUE)  # use only models that were found to be useful (had weights)


# start with y_test


# set seed - option will set same seed across multiple cores
set.seed(44, "L'Ecuyer-CMRG")
# Identify number of cores to use
n_cores <- parallelly::availableCores() - 1

# Plan separate session 
plan(multisession, workers = n_cores)

# Set seed - option will set same seed across multiple cores
set.seed(44, "L'Ecuyer-CMRG")

# Cross-validation across cores
cv_sl = CV.SuperLearner(Y = y_train, 
                        X = x_train, 
                        family = binomial(),
                        V = 15,                   # 
                        parallel = 'multicore',   # Still use 'multicore' with SuperLearner
                        SL.library = sl_libs)     # my chosen algorithms
# Confusion Matrix (keep your original code)
validation <- 
  y_test %>%
  # add our predictions - first column of predictions
  bind_cols(preds$pred[,1]) %>% 
  # rename columns
  rename(obs = `...1`,      # actual observations 
         pred = `...2`) %>% # predicted prob
  # change pred column so that obs above .5 are 1, otherwise 0
  mutate(pred = ifelse(pred >= .5, 
                       1,
                       0))

# Create confusion matrix
conf_matrix <- caret::confusionMatrix(as.factor(validation$pred), as.factor(validation$obs))
conf_matrix

# Clean up parallel workers when done
plan(sequential)
```

## Discussion Questions

\begin{enumerate}
    \item Why should we, in general, prefer the SuperLearner ensemble to the discrete winner in cross-validation? Or in other words, what is the advantage of "blending" algorithms together and giving them each weights, rather than just using the single best algorithm (with best being defined as minimizing risk)?
\end{enumerate}

# Targeted Maximum Likelihood Estimation

## Causal Diagram

TMLE requires estimating two models:

\begin{enumerate}
    \item The outcome model, or the relationship between the outcome and the treatment/predictors, $P(Y|(A,W)$.
    \item The propensity score model, or the relationship between assignment to treatment and predictors $P(A|W)$
\end{enumerate}

Using ggdag and daggity, draw a directed acylcic graph (DAG) that describes the relationships between the outcome, treatment, and covariates/predictors. Note, if you think there are covariates that are not related to other variables in the dataset, note this by either including them as freestanding nodes or by omitting them and noting omissions in your discussion.
```{r}
# DAG for TMLE
heart_dag <- 
  heart_disease %>%
  select(-ends_with("_2"))
colnames(heart_dag)
```
I found this quite hard not because I thought some things were unrelated like the instructions suggested, but because everything feels related, but it feels hard to untangle the question of direct effects on outcome versus indirect effects. It's also a bit confusing for me because from the PDF I wasn't clear if the blood_pressure_medication tretament (0,1) indicates that the person was offered a medication and potentially didn't take it, or if they might not have been offered it at all. For the former, then there's maybe differences in personal attributes that makes someone more reticent to take medication (race? age? college education?), but for the latter, maybe it's differences in personal attributes that makes a physician less likely to prescribe a patient medication, perhaps due to discrimination (race? sex at birth? income? bmi?). Because if a physician was just going off of tangible, bio/social metrics of the likelihood of heart disease (based on a person's bmi, race, age, cholesterol, sex at birth, and measured blood pressure) when they choose to prescribe someone medication or instead tell them to do exercise more or something like that, then that's a more straightforward story. But if the physician is introducing bias, for example by telling someone with a low bmi but high blood pressure and cholesterol to just exercise more instead of prescribing them medication for something genetic, with assumption that because they're 'healthy looking' medication is not necessary, that's a different story. I guess maybe it doesn't matter since they're both mediators, they just have slightly different nodes? I'm also not a doctor so I don't really know the relationship between blood pressure and cholesterol, do people naturally have high cholesterol without high blood pressure or vice versa? 
Okay looking back at the instructions, I guess this line of thought actually makes sense because TMLE has the outcome and propensity score models. So there's outcome ~ treatment/predictors and then treatment ~ predictors.
 

```{r}
# DAG for TMLE
library(dagitty)
library(ggdag)
library(stringr)

# set dag theme
# ----------
theme_set(theme_dag())
# Load necessary packages
library(dagitty)
library(ggdag)
#I saw this structure of DAG on the internet so let's try it 
heart_dag <- ggdag::dagify(
#Outcome
#Mortality is directly related to whether or not someone takes blood pressure medication, assuming that these other factors (e.g. cholesterol, bmi) are only impacting mortality from heart disease through whether or not someone is taking the blood pressure medication 
mortality ~ blood_pressure_medication,
#Treatment
#People are prescribed blood pressure medication based on the following risk factors/measures:
blood_pressure_medication ~ age + bmi + sex_at_birth + simplified_race + chol + blood_pressure,
#Mediators
#But that bmi, blood pressure, and cholesterol are related to race, college education, sex at birth, and income (food deserts, less time to exercise, stress, pressure to diet, etc.) 
#Again to simplify things, I'm going to say that BMI is related to race, college education, and income and then further that cholesterol and blood pressure are related to BMI
#Again, not sure how cholesterol and blood pressure are related so I'm going to map them separately
#I guess age is not really in my 'social' (i.e. indirect) factors, obviously age is related to income and college education but I guess I don't find that to be a meaningful relationship that it needs its own sub-mediator
bmi ~ simplified_race + college_educ + income_thousands +sex_at_birth,
chol~ bmi,
blood_pressure ~ bmi,
#And social factors
income_thousands ~ simplified_race + college_educ + sex_at_birth,
college_educ ~ simplified_race,

                                 labels = c("mortality" = "Mortality", 
                                            "blood_pressure_medication" = "Blood\n Pressure\n Meds",
                                            "chol" = "Cholesterol",
                                            "bmi" = "BMI",
                                            "sex_at_birth" = "SAB",
                                            "college_educ" = "College",
                                            "simplified_race" = "Race",
                                            "blood_pressure" = "Blood\n Pressure",
                                            "income_thousands" = "Income",
                                            "age"= "Age")
)
 
ggdag::ggdag(heart_dag, #dag object
              text = FALSE, # this means the original names won't be shown
              use_labels = "label") + # instead use the new names
   theme_void()
```

So this is messy! And this was the simplified version! Let's chart one more DAG that is a little more straightforward.

```{r}
##NOTE FOR TAYLOR: Update DAG to control plot
simple_dag <- ggdag::dagify(
  # Core relationships
  mortality ~ blood_pressure_medication,
  blood_pressure_medication ~ chol_BP + age_SAB,  #assuming that the only way BMI is impacting clinical risk is through its effect on cholesterol/BP. I personally think that's a fair assumption, but maybe there's stronger evidence that BMI is related to genetics. In other words, saying that cholesterol and BP both have independent effects on clinical risk (e.g. genetics) that are unrelated to BMI. 
  
  # Simplified mediators of selection into treatment
  #Sociodemographic impact on health measures
  bmi ~ race + income, # Assuming that BMI is related to race/income
  chol_BP ~ bmi,

  # Add labels
  labels = c(
    "mortality" = "Mortality", 
    "blood_pressure_medication" = "BP Meds",
    "chol_BP" = "BP/Chol",
    "bmi" = "BMI",
    "race" = "Race",
    "age_SAB" = "Age/SAB",
    "income" = "Income"  
  ),
  
  # Specify exposure and outcome for highlighting
  exposure = "blood_pressure_medication",
  outcome = "mortality"
)

# Visualize 
ggdag::ggdag(simple_dag, #dag object
              text = FALSE, # this means the original names won't be shown
              use_labels = "label") + # instead use the new names
   theme_dag()
```

## TMLE Estimation

Use the `tmle` package to estimate a model for the effect of blood pressure medication on the probability of mortality. Do the following:

\begin{enumerate}
    \item Use the same SuperLearner library you defined earlier
    \item Use the same outcome model and propensity score model that you specified in the DAG above. If in your DAG you concluded that it is not possible to make a causal inference from this dataset, specify a simpler model and note your assumptions for this step.
    \item Report the average treatment effect and any other relevant statistics
\end{enumerate}

```{r}
# set seed for reproducibility
set.seed(1000)

# implement above all in one step using tmle
# ----------
tmle_fit <-
  tmle::tmle(Y = Y,                  # outcome
             A = A,                  # treatment
             W = W,                  # baseline covariates
             Q.SL.library = sl_libs, # libraries for initial estimate 
             g.SL.library = sl_libs) # libraries for prob to be in treatment

# view results 
tmle_fit
```

## Discussion Questions

\begin{enumerate}
    \item What is a "double robust" estimator? Why does it provide a guarantee of consistency if either the outcome model or propensity score model is correctly specified? Or in other words, why does mispecifying one of the models not break the analysis? \textbf{Hint}: When answering this question, think about how your introductory statistics courses emphasized using theory to determine the correct outcome model, and in this course how we explored the benefits of matching.
\end{enumerate}

# LTMLE Estimation

Now imagine that everything you measured up until now was in "time period 1". Some people either choose not to or otherwise lack access to medication in that time period, but do start taking the medication in time period 2. Imagine we measure covariates like BMI, blood pressure, and cholesterol at that time for everyone in the study (indicated by a "_2" after the covariate name). 

## Causal Diagram

Update your causal diagram to incorporate this new information. \textbf{Note}: If your groups divides up sections and someone is working on LTMLE separately from TMLE then just draw a causal diagram even if it does not match the one you specified above.

\textbf{Hint}: Check out slide 27 from Maya's lecture, or slides 15-17 from Dave's second slide deck in week 8 on matching.

\textbf{Hint}: Keep in mind that any of the variables that end in "\_2" are likely affected by both the previous covariates and the first treatment when drawing your DAG.

```{r}
# DAG for TMLE

```

## LTMLE Estimation

Use the `ltmle` package for this section. First fit a "naive model" that \textbf{does not} control for the time-dependent confounding. Then run a LTMLE model that does control for any time dependent confounding. Follow the same steps as in the TMLE section. Do you see a difference between the two estimates?

```{r}
## Naive Model (no time-dependent confounding) estimate

## LTMLE estimate
```

## Discussion Questions

\begin{enumerate}
    \item What sorts of time-dependent confounding should we be especially worried about? For instance, would we be concerned about a running variable for age the same way we might be concerned about blood pressure measured at two different times?
\end{enumerate}

