---
title: "Project_8_Submission"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,      # suppress warnings
  message = FALSE,      # suppress messages
  echo = TRUE,          # show code
  cache = TRUE
)

# Add to this package list for additional SL algorithms
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  tidyverse,
  ggthemes,
  ltmle,
  tmle,
  SuperLearner,
  tidymodels,
  caret,
  dagitty,
  ggdag,
  here)
# Set a CRAN mirror
options(repos = c(CRAN = "https://cloud.r-project.org"))
#install.packages(c("future", "furrr"))
library(here)
library(tidyverse)
here()
#REMINDER: Change here on desktop
heart_disease <- readr::read_csv(here("heart_disease_tmle.csv"))
colnames(heart_disease)
# set seed
# ----------
set.seed(44)
```

# Introduction

Heart disease is the leading cause of death in the United States, and treating it properly is an important public health goal. However, it is a complex disease with several different risk factors and potential treatments. Physicians typically recommend changes in diet, increased exercise, and/or medication to treat symptoms, but it is difficult to determine how effective any one of these factors is in treating the disease. In this project, you will explore SuperLearner, Targeted Maximum Likelihood Estimation (TMLE), and Longitudinal Targeted Maximum Likelihood Estimation (LTMLE). Using a simulated dataset, you will explore whether taking blood pressure medication reduces mortality risk. 

# Data

This dataset was simulated using R (so it does not come from a previous study or other data source). It contains several variables:

\begin{itemize}
    \item \textbf{blood\_pressure\_medication}: Treatment indicator for whether the individual took blood pressure medication (0 for control, 1 for treatment)
    \item \textbf{mortality}: Outcome indicator for whether the individual passed away from complications of heart disease (0 for no, 1 for yes)
    \item \textbf{age}: Age at time 1
    \item \textbf{sex\_at\_birth}: Sex assigned at birth (0 female, 1 male)
    \item \textbf{simplified\_race}: Simplified racial category. (1: White/Caucasian, 2: Black/African American, 3: Latinx, 4: Asian American, \newline 5: Mixed Race/Other)
    \item \textbf{income\_thousands}: Household income in thousands of dollars
    \item \textbf{college\_educ}: Indicator for college education (0 for no, 1 for yes)
    \item \textbf{bmi}: Body mass index (BMI)
    \item \textbf{chol}: Cholesterol level
    \item \textbf{blood\_pressure}: Systolic blood pressure 
    \item \textbf{bmi\_2}: BMI measured at time 2
    \item \textbf{chol\_2}: Cholesterol measured at time 2
    \item \textbf{blood\_pressure\_2}: BP measured at time 2
    \item \textbf{blood\_pressure\_medication\_2}: Whether the person took treatment at time period 2 
\end{itemize}

For the "SuperLearner" and "TMLE" portions, you can ignore any variable that ends in "\_2", we will reintroduce these for LTMLE.

# SuperLearner

## Modeling

Fit a SuperLearner model to estimate the probability of someone dying from complications of heart disease, conditional on treatment and the relevant covariates. Do the following:

\begin{enumerate}
    \item Choose a library of at least 5 machine learning algorithms to evaluate. \textbf{Note}: We did not cover how to hyperparameter tune constituent algorithms within SuperLearner in lab, but you are free to do so if you like (though not required to for this exercise). 
    \item Split your data into train and test sets.
    \item Train SuperLearner
    \item Report the risk and coefficient associated with each model, and the performance of the discrete winner and SuperLearner ensemble
    \item Create a confusion matrix and report your overall accuracy, recall, and precision
\end{enumerate}

```{r}
# Fit SuperLearner Model
#listWrappers()
## sl lib
#install.packages("SuperLearner")
#install.packages(c("gam", "earth"))
#install.packages("ranger")
library("SuperLearner")
#Picking different algorithms because three had coefficients of zero lol
sl_libs <- c('SL.mean', 'SL.glm', 'SL.earth', 'SL.ranger', 'SL.step')

library(future)
#library(furrr)
## Train/Test split
# initial split
# ----------
heart_split <- 
  initial_split(heart_disease, prop = 3/4) # create initial split (tidymodels)


# Training 
# ----------
train <- 
  # Declare the training set with rsample::training()
  training(heart_split)

# y_train 
y_train <- train %>% 
  pull(mortality)  

# x_train  
x_train <-
  train %>%
  # drop the target variable
  select(-mortality, -ends_with("_2"))  

# Testing 
# ----------
test <-  
  # Declare the training set with rsample::training()
  testing(heart_split)

# y test
y_test <- test %>%
  pull(mortality)

# x test
x_test <- 
  test %>%
  select(-mortality, -ends_with("_2"))

## Train SuperLearner
# LASSO 
# ----------
sl_lasso <- SuperLearner(Y = y_train,              # target
                         X = x_train,              # features
                         family = binomial(),      # binomial : 1,0s
                         SL.library = "SL.glmnet") # find the glmnet algo from SL

# view
sl_lasso
## Risk and Coefficient of each model
# Here is the risk of the best model (discrete SuperLearner winner).
# Use which.min boolean to find minimum cvRisk in list
sl_lasso$cvRisk[which.min(sl_lasso$cvRisk)]
## Discrete winner and superlearner ensemble performance
# set seed
set.seed(987)

# multiple models  
# ----------
sl = SuperLearner(Y = y_train,
                  X = x_train,
                  family = binomial(),
                  # notice these models are concatenated
                  SL.library =sl_libs)
sl
sl$cvRisk[which.min(sl$cvRisk)]
# predictions
# ----------
preds <- 
  predict(sl,             # use the superlearner not individual models
          x_test,         # prediction on test set
          onlySL = TRUE)  # use only models that were found to be useful (had weights)


# start with y_test


# set seed - option will set same seed across multiple cores
set.seed(44, "L'Ecuyer-CMRG")
# Identify number of cores to use
n_cores <- parallelly::availableCores() - 1

# Plan separate session 
plan(multisession, workers = n_cores)

# Set seed - option will set same seed across multiple cores
set.seed(44, "L'Ecuyer-CMRG")

# Cross-validation across cores
cv_sl = CV.SuperLearner(Y = y_train, 
                        X = x_train, 
                        family = binomial(),
                        V = 15,                   # 
                        parallel = 'multicore',   # Still use 'multicore' with SuperLearner
                        SL.library = sl_libs)     # my chosen algorithms
# Confusion Matrix 
validation <- 
  y_test %>%
  # add our predictions - first column of predictions
  bind_cols(preds$pred[,1]) %>% 
  # rename columns
  rename(obs = `...1`,      # actual observations 
         pred = `...2`) %>% # predicted prob
  # change pred column so that obs above .5 are 1, otherwise 0
  mutate(pred = ifelse(pred >= .5, 
                       1,
                       0))

# Create confusion matrix
conf_matrix <- caret::confusionMatrix(as.factor(validation$pred), as.factor(validation$obs))
conf_matrix

# Clean up parallel workers when done
plan(sequential)
```
So 57.3% accuracy, I'm not sure if that's horrible but it's certainly not great, and it's even worse when we look at the confusion matrix and corresponding metrics...sensitivity is .2285 and negative prediction value is .5473 so it's really not good with the 0s.
Risk is all around .23-.24 for the models and lower risk is better, so seems not that bad? But only three of the models are contributing (the earth, RF with ranger, and glm). I wanted to get crazier with the models I chose but everything was taking so long! This notebook in general took so long to run.
## Discussion Questions

\begin{enumerate}
    \item Why should we, in general, prefer the SuperLearner ensemble to the discrete winner in cross-validation? Or in other words, what is the advantage of "blending" algorithms together and giving them each weights, rather than just using the single best algorithm (with best being defined as minimizing risk)?
\end{enumerate}
The superlearner can use the different benefits of the different models (provided you vary the models, I clearly didn't do that enough here since two didn't contribute at all) to (hopefully) lead to better accuracy, whereas the discrete winner may minimize risk, but relies (obviously) only on that algorithm and its different assumptions. 
# Targeted Maximum Likelihood Estimation

## Causal Diagram

TMLE requires estimating two models:

\begin{enumerate}
    \item The outcome model, or the relationship between the outcome and the treatment/predictors, $P(Y|(A,W)$.
    \item The propensity score model, or the relationship between assignment to treatment and predictors $P(A|W)$
\end{enumerate}

Using ggdag and daggity, draw a directed acylcic graph (DAG) that describes the relationships between the outcome, treatment, and covariates/predictors. Note, if you think there are covariates that are not related to other variables in the dataset, note this by either including them as freestanding nodes or by omitting them and noting omissions in your discussion.
```{r}
# DAG for TMLE
heart_dag <- 
  heart_disease %>%
  select(-ends_with("_2"))
```
I found this quite hard, not because I thought some things were unrelated like the instructions suggested, but because everything feels related, but it feels hard to untangle the question of direct effects on outcome versus indirect effects. It's also a bit confusing for me because from the PDF I wasn't clear if the blood_pressure_medication tretament (0,1) indicates that the person was offered a medication and potentially didn't take it, or if they might not have been offered it at all. For the former, then there's maybe differences in personal attributes that makes someone more reticent to take medication (race? age? college education?), but for the latter, maybe it's differences in personal attributes that makes a physician less likely to prescribe a patient medication, perhaps due to discrimination (race? sex at birth? income? bmi?). Because if a physician was just going off of tangible, bio/social metrics of the likelihood of heart disease (based on a person's bmi, race, age, cholesterol, sex at birth, and measured blood pressure) when they choose to prescribe someone medication or instead tell them to do exercise more or something like that, then that's a more straightforward story. But if the physician is introducing bias, for example by telling someone with a low bmi but high blood pressure and cholesterol to just exercise more instead of prescribing them medication for something genetic, with assumption that because they're 'healthy looking' medication is not necessary, that's a different story. I guess maybe it doesn't matter since they're both mediators, they just have slightly different nodes? I'm also not a doctor so I don't really know the relationship between blood pressure and cholesterol, do people naturally have high cholesterol without high blood pressure or vice versa? 
Okay looking back at the instructions, I guess this line of thought actually makes sense because TMLE has the outcome and propensity score models. So there's outcome ~ treatment/predictors and then treatment ~ predictors.
 

```{r}
# DAG for TMLE
library(dagitty)
library(ggdag)
library(stringr)

# set dag theme
# ----------
theme_set(theme_dag())
# Load necessary packages
library(dagitty)
library(ggdag)
#I saw this structure of DAG on the internet so let's try it 
heart_dag <- ggdag::dagify(
#Outcome
#Mortality is directly related to whether or not someone takes blood pressure medication, assuming that these other factors (e.g. cholesterol, bmi) are only impacting mortality from heart disease through whether or not someone is taking the blood pressure medication 
mortality ~ blood_pressure_medication,
#Treatment
#People are prescribed blood pressure medication based on the following risk factors/measures:
blood_pressure_medication ~ age + bmi + sex_at_birth + simplified_race + chol + blood_pressure,
#Mediators
#But that bmi, blood pressure, and cholesterol are related to race, college education, sex at birth, and income (food deserts, less time to exercise, stress, pressure to diet, etc.) 
#Again to simplify things, I'm going to say that BMI is related to race, college education, and income and then further that cholesterol and blood pressure are related to BMI
#Again, not sure how cholesterol and blood pressure are related so I'm going to map them separately
#I guess age is not really in my 'social' (i.e. indirect) factors, obviously age is related to income and college education but I guess I don't find that to be a meaningful relationship that it needs its own sub-mediator
bmi ~ simplified_race + college_educ + income_thousands +sex_at_birth,
chol~ bmi,
blood_pressure ~ bmi,
#And social factors
income_thousands ~ simplified_race + college_educ + sex_at_birth,
college_educ ~ simplified_race,

                                 labels = c("mortality" = "Mortality", 
                                            "blood_pressure_medication" = "Blood\n Pressure\n Meds",
                                            "chol" = "Cholesterol",
                                            "bmi" = "BMI",
                                            "sex_at_birth" = "SAB",
                                            "college_educ" = "College",
                                            "simplified_race" = "Race",
                                            "blood_pressure" = "Blood\n Pressure",
                                            "income_thousands" = "Income",
                                            "age"= "Age")
)
 
ggdag::ggdag(heart_dag, #dag object
              text = FALSE, # this means the original names won't be shown
              use_labels = "label") + # instead use the new names
   theme_void()
```

So this is messy! And this was the simplified version! Let's chart one more DAG that is a little more straightforward.
```{r}
#Create functions for future DAGs
#I tried to do the pretty DAG but it wasn't working with my relationships
# Define helper functions once at the top
get_edge_coords <- function(edges, nodes) {
  do.call(rbind, lapply(1:nrow(edges), function(i) {
    from_node <- nodes[nodes$name == edges$from[i], ]
    to_node <- nodes[nodes$name == edges$to[i], ]
    data.frame(
      x = from_node$x,
      y = from_node$y,
      xend = to_node$x,
      yend = to_node$y
    )
  }))
}

plot_custom_dag <- function(nodes, edges, node_colors, size = 16, text_size = 3.0,
                            xlim = c(0, 7), ylim = c(-1, 11)) {
  edge_coords <- get_edge_coords(edges, nodes)
  
  ggplot() +
    geom_segment(data = edge_coords, 
                 aes(x = x, y = y, xend = xend, yend = yend),
                 arrow = arrow(length = unit(0.3, "cm"), type = "closed"),
                 color = "black", size = 0.8) +
    geom_point(data = nodes, 
               aes(x = x, y = y, color = type), 
               size = size) +
    geom_text(data = nodes,
              aes(x = x, y = y, label = label),
              color = "white", size = text_size) +
    scale_color_manual(values = node_colors) +
    theme_void() +
    theme(legend.position = "none",
          plot.margin = margin(30, 30, 30, 30, "pt")) +
    coord_fixed(ratio = 1, expand = TRUE, xlim = xlim, ylim = ylim)
}
```


```{r}
simple_dag <- ggdag::dagify(
  # Core relationships
  mortality ~ blood_pressure_medication,
  blood_pressure_medication ~ chol_BP + age_SAB,  #assuming that the only way BMI is impacting clinical risk is through its effect on cholesterol/BP. I personally think that's a fair assumption, but maybe there's stronger evidence that BMI is related to genetics. In other words, saying that cholesterol and BP both have independent effects on clinical risk (e.g. genetics) that are unrelated to BMI. 
  #combining age and SAB because race and income have no relationship to them, but race and income do have a relationship to cholesterol and blood pressure. Probably a better way to do this...
  
  # Simplified mediators of selection into treatment
  #Sociodemographic impact on health measures
  bmi ~ race + income, # Assuming that BMI is related to race/income
  chol_BP ~ bmi,

  # Add labels
  labels = c(
    "mortality" = "Mortality", 
    "blood_pressure_medication" = "BP Meds",
    "chol_BP" = "BP/Chol",
    "bmi" = "BMI",
    "race" = "Race",
    "age_SAB" = "Age/SAB",
    "income" = "Income"  
  ),
  
  # Specify exposure and outcome for highlighting
  exposure = "blood_pressure_medication",
  outcome = "mortality"
)
# Create diagram manually for more precise control
library(ggplot2)
library(grid)

# Define node positions (Idk this is what Claude told me to do when I couldn't map out the relationships simply, I had to manually plot them the way I wanted)
# Define nodes
nodes <- data.frame(
  name = c("mortality", "blood_pressure_medication", "chol_BP", "age_SAB", "bmi", "race", "income"),
  label = c("Mortality", "BP Meds", "BP/Chol", "Age/SAB", "BMI", "Race", "Income"),
  x = c(3, 3, 1, 5, 3, 1.5, 4.5),
  y = c(0.5, 2.5, 4, 4, 5.5, 7, 7),
  type = c("outcome", "treatment", "other", "other", "other", "other", "other")
)

# Define edges
edges <- data.frame(
  from = c("race", "income", "bmi", "chol_BP", "age_SAB", "blood_pressure_medication", 
           "race", "income"),
  to = c("bmi", "bmi", "chol_BP", "blood_pressure_medication", "blood_pressure_medication", "mortality",
         "blood_pressure_medication", "blood_pressure_medication")
)

# Merge to get coordinates for arrows
edges_coords <- merge(edges, nodes, by.x = "from", by.y = "name")
edges_coords <- merge(edges_coords, nodes, by.x = "to", by.y = "name", suffixes = c("_from", "_to"))

# Plot
ggplot() +
  # Arrows
  geom_segment(
    data = edges_coords,
    aes(x = x_from, y = y_from, xend = x_to, yend = y_to),
    arrow = grid::arrow(length = grid::unit(0.25, "cm")),
    size = 0.6,
    color = "black"
  ) +
  # Nodes with larger points
  geom_point(
    data = nodes,
    aes(x = x, y = y, color = type),
    size = 20  
  ) +
  # Labels
  geom_text(
    data = nodes,
    aes(x = x, y = y, label = label),
    size = 3,
    color = "white"
  ) +
  scale_color_manual(values = c(
    "treatment" = "#d9534f",
    "outcome" = "#5bc0de",
    "other" = "darkgrey"
  )) +
  xlim(0, 6) + ylim(0, 8) +
  theme_void() +
  theme(legend.position = "none")
```
My arrows won't work : (
I'm not sure if I actually believe these are the relationships between variables, but this is my model for simplicity's sake. It goes like this:
BMI is related to race and income, but not entirely causal (ex. exercise). Someone's blood pressure/cholesterol levels are related to their BMI, but not entirely (ex. genetic factors unrelated to race). Someone receives BP meds based on their blood pressure, cholesterol levels, their age, and their sex at birth, because this is what a physician observes when the patient is screened. Blood pressure and cholesterol are separated from age and sex at birth because although all four are clinical risk factors (e.g. what a physician looks at when they're screening), the former pairing is influenced by race and income whereas the latter pairing is not. So, this is assuming that race and income only affect cholesterol/blood pressure through their effect on BMI. Again, maybe this is not a fair assumption and that race has a relationship to genetic predisposition to high blood pressure/cholesterol, but I'm not going to make that assumption without domain knowledge.We might also say that race and income impact selection into treatment not only through their effects on BMI, but also directly (through access to healthcare, medical racism, etc.), so we also have direct links from race/income to BP meds, which means that race/income influence treatment not just through their impact on BMI, but also through those selection mechanisms. It's also assuming that BMI impacts treatment/mortality through its affect on cholesterol/BP which may not be fair; BMI could ostensibly impact selection into treatment if doctors treat patients with higher BMIs differently not just because of those patients' higher cholesterol/BP levels, but also due to fatphobia (e.g. suggesting diet/exercise change before medication), but I'm ignoring that for now... I also left out college education since I'm going to say that the only way that's impacting things is through income (though we might hypothesize how college education makes people more/less likely to receive treatment..)
## TMLE Estimation

Use the `tmle` package to estimate a model for the effect of blood pressure medication on the probability of mortality. Do the following:

\begin{enumerate}
    \item Use the same SuperLearner library you defined earlier
    \item Use the same outcome model and propensity score model that you specified in the DAG above. If in your DAG you concluded that it is not possible to make a causal inference from this dataset, specify a simpler model and note your assumptions for this step.
    \item Report the average treatment effect and any other relevant statistics
\end{enumerate}



```{r}
# set seed for reproducibility
set.seed(1000)

# implement using tmle
# ----------
sl_libs <- c('SL.mean', 'SL.glm', 'SL.earth', 'SL.ranger', 'SL.step')

# Prepare data for TMLE
# Remove variables with suffix "_2" (follow-up measurements)
heart_tmle <- heart_disease %>%
  select(-ends_with("_2"))

# Convert categorical variables to factors
heart_tmle <- heart_tmle %>%
  mutate(
    sex_at_birth = as.factor(sex_at_birth),
    simplified_race = as.factor(simplified_race),
  )

# Define outcome and treatment
Y <- heart_tmle$mortality                     # Outcome 
A <- heart_tmle$blood_pressure_medication     # Treatment 

# Define W based on DAG
W <- heart_tmle %>%
  select(
    # Socioedemographic baseline covariates 
    income_thousands, simplified_race, 
    #Clinical baseline covariates 
    age, sex_at_birth, 
    # Clinical Time_1-measured covariates 
    bmi, blood_pressure, chol
  ) %>%
  as.data.frame()


# Run TMLE 
set.seed(123)
tmle_dag_result <- tmle::tmle(
  Y = Y,                      # Outcome: mortality
  A = A,                      # Treatment: blood pressure medication
  W = W,                      # Covariates
  Q.SL.library = sl_libs,     # SuperLearner library for outcome model
  g.SL.library = sl_libs,     # SuperLearner library for propensity score model
  verbose = TRUE              # Show progress
)

# Safely extract and coerce values
ate_value <- as.numeric(tmle_dag_result$estimates$ATE$psi)
ci_lower  <- as.numeric(tmle_dag_result$estimates$ATE$CI[1])
ci_upper  <- as.numeric(tmle_dag_result$estimates$ATE$CI[2])
p_value   <- as.numeric(tmle_dag_result$estimates$ATE$pvalue)

# Check all are numeric
stopifnot(is.numeric(ate_value), is.numeric(ci_lower), is.numeric(ci_upper), is.numeric(p_value))

# Build the table
results_table <- data.frame(
  Measure = c("Average Treatment Effect (ATE)", 
              "95% Confidence Interval Lower", 
              "95% Confidence Interval Upper",
              "P-value"),
  Value = c(round(ate_value, 4), 
            round(ci_lower, 4), 
            round(ci_upper, 4),
            round(p_value, 4))
)

# Print to console
print(results_table, row.names = FALSE)
```
Okay, my ATE is -0.3611 which means that on average, taking the blood pressure medication decreased likelihood of mortality by 36.11% and with the treatment on the treated, the effect is about 75%. We also see that for those who didn't receive treatment, there would be an average 37% decreased  likelihood if they received treatment, which I'm assuming will come into play later when we do the time_2 analysis. 
## Discussion Questions

\begin{enumerate}
    \item What is a "double robust" estimator? Why does it provide a guarantee of consistency if either the outcome model or propensity score model is correctly specified? Or in other words, why does mispecifying one of the models not break the analysis? \textbf{Hint}: When answering this question, think about how your introductory statistics courses emphasized using theory to determine the correct outcome model, and in this course how we explored the benefits of matching.
\end{enumerate}
If I remember from our discussion on this, I think double robust estimator (why do I remember us calling it doubly robust estimator?) was sort of the best of both worlds, because it basically has a guarantee of having an unbiased estimate if either the outcome OR propensity score model is correctly specified, so you can essentially "get it wrong" with respect to one of the two models and still have an unbiased estimator because if your outcome model is correct but your propensity score model is mispecified, the outcome model still has the true relationship between the outcome and treatment. I am less sure about how this works in the other direction, if your propensity score model is correct but the outcome model is mispecified, because how do you understand the propensity score model but not the outcome model? Isn't the propensity score model "harder" to model, theoretically? But either way, if you somehow can correctly specify the propensity score model but not the outcome, I think it makes intuitive sense that you can somehow learn something about the relationship between treatment and outcome still. 

# LTMLE Estimation
Now imagine that everything you measured up until now was in "time period 1". Some people either choose not to or otherwise lack access to medication in that time period, but do start taking the medication in time period 2. Imagine we measure covariates like BMI, blood pressure, and cholesterol at that time for everyone in the study (indicated by a "_2" after the covariate name). 

```{r}
colnames(heart_disease)
```


## Causal Diagram

Update your causal diagram to incorporate this new information. \textbf{Note}: If your groups divides up sections and someone is working on LTMLE separately from TMLE then just draw a causal diagram even if it does not match the one you specified above.

\textbf{Hint}: Check out slide 27 from Maya's lecture, or slides 15-17 from Dave's second slide deck in week 8 on matching.

\textbf{Hint}: Keep in mind that any of the variables that end in "\_2" are likely affected by both the previous covariates and the first treatment when drawing your DAG.

So I was imagining that the order of things was: someone goes to the doctors office, the doctor measures their BP_1, BMI_1, and cholesterol_1, then they either receive the treatment or don't (A1). Then I thought someone would go back to the doctor's office at time_2, then measure their BP_2, BMI_2, and cholesterol_2 to see if those numbers changed before deciding whether the patient should now get the treatment, and then after those second measurements are taken, then treatment (A2). 

```{r}
#LTME DAG
library(dplyr)

# DAG showing time 1 and time 2 
extended_dag <- ggdag::dagify(
  # Core relationships
  mortality ~ blood_pressure_medication_1 + blood_pressure_medication_2,
  blood_pressure_medication_1 ~ chol_BP_1 + age_SAB + bmi_1,
  blood_pressure_medication_2 ~ chol_BP_2 + blood_pressure_medication_1 + bmi_2 + age_SAB,
  chol_BP_1 ~ bmi_1,
  chol_BP_2 ~ bmi_2 + blood_pressure_medication_1 + chol_BP_1,
  bmi_1 ~ race + income,
  bmi_2 ~ bmi_1 + blood_pressure_medication_1,
  
  # Add labels
  labels = c(
    "mortality" = "Mortality", 
    "blood_pressure_medication_1" = "BP Meds_1",
    "blood_pressure_medication_2" = "BP Meds_2",
    "chol_BP_1" = "BP/Chol_1",
    "chol_BP_2" = "BP/Chol_2",
    "bmi_1" = "BMI_1",
    "bmi_2" = "BMI_2",
    "race" = "Race",
    "age_SAB" = "Age/SAB",
    "income" = "Income"  
  ),
  
  # Specify exposures and outcome for highlighting
  exposure = c("blood_pressure_medication_1", "blood_pressure_medication_2"),
  outcome = "mortality"
)

library(ggplot2)

# Node positions
nodes <- data.frame(
  name = c(
    "race", "income", "age_SAB",
    "bmi_1", "chol_BP_1",
    "blood_pressure_medication_1",
    "bmi_2", "chol_BP_2",
    "blood_pressure_medication_2",
    "mortality"
  ),
  label = c(
    "Race", "Income", "Age/SAB",
    "BMI_1", "BP/Chol_1",
    "BP Meds_1",
    "BMI_2", "BP/Chol_2",
    "BP Meds_2",
    "Mortality"
  ),
  x = c(1, 3.5, 6, 2, 5, 3.5, 2, 5, 3.5, 3.5),
  y = c(10, 10, 10, 8, 8, 6, 4, 4, 2, 0),
  type = c(
    "other", "other", "other",
    "other", "other",
    "treatment_1",
    "other", "other",
    "treatment_2",
    "outcome"
  )
)

# Edges
edges <- data.frame(
  from = c(
    "race", "income",
    "bmi_1", "bmi_1",
    "chol_BP_1", "age_SAB",
    "blood_pressure_medication_1", "blood_pressure_medication_1",
    "bmi_1", "chol_BP_1",
    "bmi_2", "chol_BP_2", "age_SAB",
    "blood_pressure_medication_1",
    "blood_pressure_medication_1", "blood_pressure_medication_2"
  ),
  to = c(
    "bmi_1", "bmi_1",
    "chol_BP_1", "blood_pressure_medication_1",
    "blood_pressure_medication_1", "blood_pressure_medication_1",
    "bmi_2", "chol_BP_2",
    "bmi_2", "chol_BP_2",
    "blood_pressure_medication_2", "blood_pressure_medication_2", "blood_pressure_medication_2",
    "blood_pressure_medication_2",
    "mortality", "mortality"
  )
)

# Plot the DAG
library(grid)  
# Merge to get coordinates for drawing arrows
edges_coords <- merge(edges, nodes, by.x = "from", by.y = "name")
edges_coords <- merge(edges_coords, nodes, by.x = "to", by.y = "name", suffixes = c("_from", "_to"))

# Plot the DAG with arrows
ggplot() +
  geom_segment(
    data = edges_coords,
    aes(x = x_from, y = y_from, xend = x_to, yend = y_to),
    arrow = grid::arrow(length = grid::unit(0.25, "cm")),
    size = 0.6,
    color = "black"
  ) +
  geom_point(
    data = nodes,
    aes(x = x, y = y, color = type),
    size = 20
  ) +
  geom_text(
    data = nodes,
    aes(x = x, y = y, label = label),
    size = 3,
    color = "white"
  ) +
  scale_color_manual(values = c(
    "treatment_1" = "#d9534f",
    "treatment_2" = "#FF8C00",
    "outcome" = "#5bc0de",
    "other" = "darkgrey"
  )) +
  xlim(0, 7) + ylim(-1, 11) +
  theme_void() +
  theme(legend.position = "none")
```


## LTMLE Estimation

Use the `ltmle` package for this section. First fit a "naive model" that \textbf{does not} control for the time-dependent confounding. Then run a LTMLE model that does control for any time dependent confounding. Follow the same steps as in the TMLE section. Do you see a difference between the two estimates?

```{r}
#I had to get crazy with these failsafes because I kept knitting and it would take like 3 hours to get to 90% and then crash 
# Load necessary libraries
library(dplyr)
library(ltmle)
library(SuperLearner)

# Set seed for reproducibility
set.seed(123)

# Define SuperLearner library - using simpler algorithms that won't cause failures I had to reduce them from 5 and change them around, sorry Kasey : ( it just kept breaking over and over
sl_libs <- c('SL.mean', 'SL.glm', 'SL.step')

# Prepare naive data (no Lnodes)
naive_data <- heart_disease %>%
  select(
    age, sex_at_birth, simplified_race, college_educ, income_thousands,  # Baseline covariates (W)
    blood_pressure_medication,                                           # A1
    blood_pressure_medication_2,                                         # A2
    mortality                                                            # Outcome Y
  ) %>%
  mutate(
    sex_at_birth = as.factor(sex_at_birth),
    simplified_race = as.factor(simplified_race),
    college_educ = as.factor(college_educ),
    blood_pressure_medication = as.numeric(blood_pressure_medication),
    blood_pressure_medication_2 = as.numeric(blood_pressure_medication_2),
    mortality = as.numeric(mortality)
  )

# Fit naive LTMLE with simplified parameters
ltmle_naive <- tryCatch({
  ltmle(
    data = naive_data,
    Anodes = c("blood_pressure_medication", "blood_pressure_medication_2"),
    Ynodes = "mortality",
    abar = list(treatment = c(1, 1), control = c(0, 0)),
    gbounds = c(0.05, 0.95),  # Less aggressive bounds to prevent numeric issues
    SL.library = sl_libs
  )
}, error = function(e) {
  warning(paste("Naive LTMLE failed:", e$message))
  return(NULL)
})

# Prepare full data (with Lnodes)
full_data <- heart_disease %>%
  select(
    # Baseline covariates
    age, sex_at_birth, simplified_race, college_educ, income_thousands,
    
    # Time 1 (L1, A1)
    bmi, blood_pressure, chol,
    blood_pressure_medication,
    
    # Time 2 (L2, A2)
    bmi_2, blood_pressure_2, chol_2,
    blood_pressure_medication_2,
    
    # Outcome
    mortality
  ) %>%
  mutate(
    sex_at_birth = as.factor(sex_at_birth),
    simplified_race = as.factor(simplified_race),
    college_educ = as.factor(college_educ),
    blood_pressure_medication = as.numeric(blood_pressure_medication),
    blood_pressure_medication_2 = as.numeric(blood_pressure_medication_2),
    mortality = as.numeric(mortality)
  )

# Fit full LTMLE with simplified parameters
ltmle_full <- tryCatch({
  ltmle(
    data = full_data,
    Anodes = c("blood_pressure_medication", "blood_pressure_medication_2"),
    Lnodes = c("bmi", "blood_pressure", "chol", 
               "bmi_2", "blood_pressure_2", "chol_2"),
    Ynodes = "mortality",
    abar = list(treatment = c(1, 1), control = c(0, 0)),
    SL.library = sl_libs,
    gbounds = c(0.05, 0.95)
  )
}, error = function(e) {
  cat("Full LTMLE failed:\n")
  print(e)
  return(NULL)
})

# Helper function to safely extract ATE 
extract_results <- function(model, name) {
  if (is.null(model)) {
    return(data.frame(
      Model = name,
      ATE = NA,
      CI_Lower = NA,
      CI_Upper = NA,
      P_value = NA
    ))
  }
  
  tryCatch({
    summary_obj <- summary(model)
    if (!is.null(summary_obj$effect.measures$ATE)) {
      ate_obj <- summary_obj$effect.measures$ATE
      return(data.frame(
        Model = name,
        ATE = round(ate_obj$estimate, 4),
        CI_Lower = round(ate_obj$CI[1], 4),
        CI_Upper = round(ate_obj$CI[2], 4),
        P_value = round(ate_obj$pvalue, 4)
      ))
    } else {
      return(data.frame(
        Model = name,
        ATE = NA,
        CI_Lower = NA,
        CI_Upper = NA,
        P_value = NA
      ))
    }
  }, error = function(e) {
    warning(paste("Failed to extract results for", name, ":", e$message))
    return(data.frame(
      Model = name,
      ATE = NA,
      CI_Lower = NA,
      CI_Upper = NA,
      P_value = NA
    ))
  })
}

# Extract results
naive_results <- extract_results(ltmle_naive, "Naive LTMLE")
full_results <- extract_results(ltmle_full, "Full LTMLE")

# Combine into comparison table
results_comparison <- rbind(naive_results, full_results)

# Print results
print(results_comparison)

# If both models ran successfully, test for difference between them
if (!is.na(naive_results$ATE) && !is.na(full_results$ATE)) {
  cat("\nDifference between models (Full - Naive):", 
      round(full_results$ATE - naive_results$ATE, 4))
}

```

Oh my GOD you have no idea how happy I am that this just ran in general...this absolutely killed me. For some reason R kept interrupting my environment and so I would have to start the whole notebook again. Cool, so the ATE for the full LMTLE is only slightly more negative than the naive, which is surprsing considering that the naive doesn't control for time-confounding, and we have no reason to believe that the time-confounding variables don't influence treatment/outcome.... 
## Discussion Questions

\begin{enumerate}
    \item What sorts of time-dependent confounding should we be especially worried about? For instance, would we be concerned about a running variable for age the same way we might be concerned about blood pressure measured at two different times?
    Well no, I don't think we would be worried about age in the same way that we are worried about something like blood pressure or BMI. The latter and the former groups both change over time, but the reason why we're worried about the latter is because we think that they influence treatment, can be influenced by the treatment, and then further influence the outcome. So BP_1 _> A1 -> BP_2 (Different, perhaps lower) -> A2 -> Y. So the change in BP influences their subsequent treatment status. With something like age, that would change over the treatment periods (even though we only measured it at time 1 here), but age isn't influenced by the treatment itself. I guess we can think of *some* ways, like if someone is under some cutoff of eligibility at time 1 and over at time 2. But that's kind of a different causal story from what we are assuming here. 
\end{enumerate}

